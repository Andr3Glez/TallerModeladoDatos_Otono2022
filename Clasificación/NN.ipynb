{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2022\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://bernardmarr.com/img/What%20is%20an%20Artificial%20Neural%20Networks.jpg</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Redes Neuronales para Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las redes neuronales para clasificación toman como salida valores discretos, generalmente valores binarios (0, 1)\n",
    "- Aplicar con éxito en la red neuronal a un problema de clasificación requiere que los valores de la red estén limitados en un rango de 0 y 1.\n",
    "- Una transformación no lineal es incluída en el modelo de red neuronal. Usualmente esta transformación es una función sigmoidal. \n",
    "\n",
    "**Entonces... ¿qué pasaría si tengo una red neuronal con sólo una capa, donde la función de activación es sigmoidal? sería lo mismo que aplicar una regresión logística**\n",
    "\n",
    "Red neuronal con una capa con función de activación sigmoidal = Regresión logística\n",
    "\n",
    "**Modelo matemático**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#Image(filename='capa_oculta2.JPG', width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= #66CC00>$$\\nu^{1} = w_{0}^{1}+w^{1}$$</font>\n",
    "<font color= #66CC00>$$y^{1} = \\varphi(\\nu^{1})$$</font>\n",
    "<font color= #009900>$$\\nu^{2} = w_{0}^{2}+w^{2}y_{1}$$</font>\n",
    "<font color= #009900>$$y^{2} = \\varphi(\\nu^{2})$$</font>\n",
    "<font color= #3399FF>$$\\nu^{3} = w_{0}^{3}+w^{3}y_{2}$$</font>\n",
    "<font color= #3399FF>$$y^{3} = \\varphi(\\nu^{3})$$</font>\n",
    "\n",
    "Para un problema de clasificación multiclase, el número de salidas aumenta en función del número de clases a clasificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo para salida binaria**\n",
    "\n",
    "Queremos predecir si una persona va a tener diabetes o no (Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "desc = data.describe()\n",
    "info = data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar datos para train y test\n",
    "X = data.iloc[:,0:8]\n",
    "Y = np.ravel(data['Outcome'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalar datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 1ms/step - loss: 0.7274 - accuracy: 0.5345\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 925us/step - loss: 0.7172 - accuracy: 0.5419\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 838us/step - loss: 0.7073 - accuracy: 0.5456\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.5512\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5587\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5717\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.5903\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.6015\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6182\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6276\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6452 - accuracy: 0.6350\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6462\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6499\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6574\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6592\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.6172 - accuracy: 0.6760\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6834\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6890\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6890\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6890\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6890\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6927\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7039\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.7039\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6983\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 995us/step - loss: 0.5779 - accuracy: 0.6983\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6946\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.6983\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.6983\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 845us/step - loss: 0.5663 - accuracy: 0.7002\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7039\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7095\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7132\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7132\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7114\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7151\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 990us/step - loss: 0.5499 - accuracy: 0.7151\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7169\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 925us/step - loss: 0.5462 - accuracy: 0.7188\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7207\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7225\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 863us/step - loss: 0.5406 - accuracy: 0.7244\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7244\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 748us/step - loss: 0.5373 - accuracy: 0.7263\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7281\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7300\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 982us/step - loss: 0.5325 - accuracy: 0.7318\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7337\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7337\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7356\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7356\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.7393\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.7412\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7430\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7412\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7449\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.7449\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7449\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7449\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7449\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7486\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7486\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 869us/step - loss: 0.5137 - accuracy: 0.7486\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7505\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7505\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7505\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7523\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 854us/step - loss: 0.5091 - accuracy: 0.7523\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7505\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7523\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7523\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7523\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7523\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7523\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 985us/step - loss: 0.5036 - accuracy: 0.7542\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7542\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7561\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7598\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7598\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7598\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 933us/step - loss: 0.4994 - accuracy: 0.7598\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7598\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7598\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7616\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7616\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7616\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7616\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7635\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7635\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7635\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7635\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7654\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7654\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7672\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7672\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7672\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7672\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7672\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 863us/step - loss: 0.4895 - accuracy: 0.7672\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7672\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7672\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7691\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 765us/step - loss: 0.4876 - accuracy: 0.7691\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7709\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7709\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7709\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7709\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 890us/step - loss: 0.4854 - accuracy: 0.7709\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7709\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 919us/step - loss: 0.4846 - accuracy: 0.7709\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7709\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 715us/step - loss: 0.4837 - accuracy: 0.7709\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7747\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.4830 - accuracy: 0.7765\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 976us/step - loss: 0.4827 - accuracy: 0.7765\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 805us/step - loss: 0.4824 - accuracy: 0.7765\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7765\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 704us/step - loss: 0.4818 - accuracy: 0.7765\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 949us/step - loss: 0.4814 - accuracy: 0.7765\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 808us/step - loss: 0.4810 - accuracy: 0.7747\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7747\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 723us/step - loss: 0.4803 - accuracy: 0.7747\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 619us/step - loss: 0.4800 - accuracy: 0.7747\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 762us/step - loss: 0.4797 - accuracy: 0.7747\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 727us/step - loss: 0.4793 - accuracy: 0.7747\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 952us/step - loss: 0.4790 - accuracy: 0.7765\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 774us/step - loss: 0.4787 - accuracy: 0.7765\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 936us/step - loss: 0.4783 - accuracy: 0.7765\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7765\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7765\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 984us/step - loss: 0.4774 - accuracy: 0.7765\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7765\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 953us/step - loss: 0.4768 - accuracy: 0.7747\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7728\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7728\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7728\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7747\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7765\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7765\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7765\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7747\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7747\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7765\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7747\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 912us/step - loss: 0.4735 - accuracy: 0.7765\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 935us/step - loss: 0.4732 - accuracy: 0.7747\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 712us/step - loss: 0.4730 - accuracy: 0.7747\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 895us/step - loss: 0.4727 - accuracy: 0.7747\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.4725 - accuracy: 0.7747\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7747\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 732us/step - loss: 0.4720 - accuracy: 0.7747\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7747\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 921us/step - loss: 0.4716 - accuracy: 0.7747\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7747\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 755us/step - loss: 0.4712 - accuracy: 0.7747\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7747\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7747\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7747\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7747\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7747\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 987us/step - loss: 0.4698 - accuracy: 0.7747\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7765\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7765\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7765\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 970us/step - loss: 0.4689 - accuracy: 0.7765\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7765\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7765\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7765\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 954us/step - loss: 0.4681 - accuracy: 0.7765\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7784\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 917us/step - loss: 0.4678 - accuracy: 0.7784\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7784\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7784\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7803\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7803\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7803\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 903us/step - loss: 0.4667 - accuracy: 0.7803\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7803\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7803\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7803\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7803\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7803\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7803\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7803\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7803\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7803\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7784\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 940us/step - loss: 0.4647 - accuracy: 0.7784\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7784\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7784\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4642 - accuracy: 0.7784\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4641 - accuracy: 0.7765\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7784\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7784\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7765\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7803\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4633 - accuracy: 0.7765\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4632 - accuracy: 0.7784\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 800us/step - loss: 0.4630 - accuracy: 0.7784\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7784\n"
     ]
    }
   ],
   "source": [
    "#Construir red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='tanh', input_shape=(8,))) #se puede cambiar la función de activación\n",
    "model.add(Dense(1, activation='sigmoid')) #La capa de salida debe ser \"\" para problemas binomiales (0 y 1)\n",
    "\n",
    "# Configuración del optimizador\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de la red neuronal\n",
    "model_history=model.fit(X_train, Y_train,epochs=200, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0.5, 0, 'Epochs'), Text(0, 0.5, 'Accuracy function'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ver el performance del modelo en el entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(122)\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.xlabel('Epochs'),plt.ylabel('Accuracy function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 857us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Usar el modelo para predecir\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32195482],\n",
       "       [0.12248121],\n",
       "       [0.10152701],\n",
       "       [0.2368149 ],\n",
       "       [0.58206534],\n",
       "       [0.52945983],\n",
       "       [0.04092223],\n",
       "       [0.5864313 ],\n",
       "       [0.6280382 ],\n",
       "       [0.78322464],\n",
       "       [0.21859825],\n",
       "       [0.81929874],\n",
       "       [0.39779267],\n",
       "       [0.36055923],\n",
       "       [0.06699404],\n",
       "       [0.3846699 ],\n",
       "       [0.09911872],\n",
       "       [0.05864189],\n",
       "       [0.6618078 ],\n",
       "       [0.5551664 ],\n",
       "       [0.26600283],\n",
       "       [0.07020407],\n",
       "       [0.3865614 ],\n",
       "       [0.0786235 ],\n",
       "       [0.51244724],\n",
       "       [0.8522351 ],\n",
       "       [0.08586954],\n",
       "       [0.06560618],\n",
       "       [0.21711515],\n",
       "       [0.12203932],\n",
       "       [0.75451523],\n",
       "       [0.81159186],\n",
       "       [0.8256758 ],\n",
       "       [0.7234291 ],\n",
       "       [0.62281483],\n",
       "       [0.7420764 ],\n",
       "       [0.8337324 ],\n",
       "       [0.3399288 ],\n",
       "       [0.5710967 ],\n",
       "       [0.49893305],\n",
       "       [0.05750085],\n",
       "       [0.6562347 ],\n",
       "       [0.5766585 ],\n",
       "       [0.39509678],\n",
       "       [0.06323494],\n",
       "       [0.6401785 ],\n",
       "       [0.70312816],\n",
       "       [0.1571359 ],\n",
       "       [0.55536526],\n",
       "       [0.92303866],\n",
       "       [0.04812579],\n",
       "       [0.72011197],\n",
       "       [0.6966744 ],\n",
       "       [0.25132886],\n",
       "       [0.23762602],\n",
       "       [0.04037312],\n",
       "       [0.7846204 ],\n",
       "       [0.07860532],\n",
       "       [0.39973   ],\n",
       "       [0.7562051 ],\n",
       "       [0.7046251 ],\n",
       "       [0.26985425],\n",
       "       [0.5550856 ],\n",
       "       [0.4612378 ],\n",
       "       [0.0751273 ],\n",
       "       [0.46968052],\n",
       "       [0.04578093],\n",
       "       [0.67164016],\n",
       "       [0.09548135],\n",
       "       [0.83378685],\n",
       "       [0.75939304],\n",
       "       [0.07075267],\n",
       "       [0.32798082],\n",
       "       [0.10075893],\n",
       "       [0.09057688],\n",
       "       [0.49580386],\n",
       "       [0.23692806],\n",
       "       [0.16706714],\n",
       "       [0.16221698],\n",
       "       [0.28008956],\n",
       "       [0.670203  ],\n",
       "       [0.10855524],\n",
       "       [0.05500556],\n",
       "       [0.3781298 ],\n",
       "       [0.26507217],\n",
       "       [0.88221866],\n",
       "       [0.7219933 ],\n",
       "       [0.42341945],\n",
       "       [0.08840082],\n",
       "       [0.06383761],\n",
       "       [0.07349321],\n",
       "       [0.26287127],\n",
       "       [0.07819939],\n",
       "       [0.3646735 ],\n",
       "       [0.49319088],\n",
       "       [0.5848906 ],\n",
       "       [0.41439438],\n",
       "       [0.10074   ],\n",
       "       [0.7096581 ],\n",
       "       [0.14866638],\n",
       "       [0.7805221 ],\n",
       "       [0.06636871],\n",
       "       [0.65427935],\n",
       "       [0.5679555 ],\n",
       "       [0.69863147],\n",
       "       [0.21479793],\n",
       "       [0.267141  ],\n",
       "       [0.79056513],\n",
       "       [0.19778132],\n",
       "       [0.48169476],\n",
       "       [0.06750105],\n",
       "       [0.3546025 ],\n",
       "       [0.08613139],\n",
       "       [0.78711456],\n",
       "       [0.18776071],\n",
       "       [0.2159507 ],\n",
       "       [0.6464442 ],\n",
       "       [0.19369918],\n",
       "       [0.06772394],\n",
       "       [0.35357374],\n",
       "       [0.08370219],\n",
       "       [0.25652197],\n",
       "       [0.16519545],\n",
       "       [0.115918  ],\n",
       "       [0.29078624],\n",
       "       [0.5275474 ],\n",
       "       [0.09541994],\n",
       "       [0.8101756 ],\n",
       "       [0.7746969 ],\n",
       "       [0.7983074 ],\n",
       "       [0.73042136],\n",
       "       [0.75924444],\n",
       "       [0.16628924],\n",
       "       [0.44590652],\n",
       "       [0.7938714 ],\n",
       "       [0.11626176],\n",
       "       [0.14273223],\n",
       "       [0.72331494],\n",
       "       [0.79079926],\n",
       "       [0.03180019],\n",
       "       [0.09159379],\n",
       "       [0.0604085 ],\n",
       "       [0.21102956],\n",
       "       [0.5761445 ],\n",
       "       [0.09932342],\n",
       "       [0.25831068],\n",
       "       [0.16936621],\n",
       "       [0.03967749],\n",
       "       [0.37930185],\n",
       "       [0.7723348 ],\n",
       "       [0.1201219 ],\n",
       "       [0.56384224],\n",
       "       [0.35433543],\n",
       "       [0.20140201],\n",
       "       [0.08223535],\n",
       "       [0.5233344 ],\n",
       "       [0.31754845],\n",
       "       [0.59145916],\n",
       "       [0.6891368 ],\n",
       "       [0.19227272],\n",
       "       [0.30596375],\n",
       "       [0.69430566],\n",
       "       [0.1722575 ],\n",
       "       [0.04555329],\n",
       "       [0.10295459],\n",
       "       [0.8217902 ],\n",
       "       [0.05040397],\n",
       "       [0.2944858 ],\n",
       "       [0.8082974 ],\n",
       "       [0.56867343],\n",
       "       [0.62727207],\n",
       "       [0.18064079],\n",
       "       [0.30657986],\n",
       "       [0.67945826],\n",
       "       [0.81481767],\n",
       "       [0.11620421],\n",
       "       [0.24747498],\n",
       "       [0.3021255 ],\n",
       "       [0.30144617],\n",
       "       [0.37455764],\n",
       "       [0.64232624],\n",
       "       [0.6208039 ],\n",
       "       [0.44228527],\n",
       "       [0.6906696 ],\n",
       "       [0.67535186],\n",
       "       [0.09003168],\n",
       "       [0.05276313],\n",
       "       [0.0997681 ],\n",
       "       [0.81050986],\n",
       "       [0.4795626 ],\n",
       "       [0.06036519],\n",
       "       [0.09285738],\n",
       "       [0.74161565],\n",
       "       [0.26814315],\n",
       "       [0.12366248],\n",
       "       [0.05571242],\n",
       "       [0.10012423],\n",
       "       [0.07220344],\n",
       "       [0.21395184],\n",
       "       [0.69740385],\n",
       "       [0.18526764],\n",
       "       [0.09713164],\n",
       "       [0.39367557],\n",
       "       [0.53749406],\n",
       "       [0.64852923],\n",
       "       [0.08942971],\n",
       "       [0.07370319],\n",
       "       [0.2130364 ],\n",
       "       [0.8793929 ],\n",
       "       [0.66039264],\n",
       "       [0.32574794],\n",
       "       [0.17104599],\n",
       "       [0.11142347],\n",
       "       [0.15418875],\n",
       "       [0.6700064 ],\n",
       "       [0.17005965],\n",
       "       [0.87514806],\n",
       "       [0.36110964],\n",
       "       [0.30551848],\n",
       "       [0.8286467 ],\n",
       "       [0.57335687],\n",
       "       [0.12182337],\n",
       "       [0.09126569],\n",
       "       [0.15763992],\n",
       "       [0.08224115],\n",
       "       [0.5761094 ],\n",
       "       [0.22407894],\n",
       "       [0.2792895 ],\n",
       "       [0.34074944],\n",
       "       [0.1580827 ],\n",
       "       [0.10791781]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 998us/step - loss: 0.5331 - accuracy: 0.7100\n",
      "[0.5331099629402161, 0.709956705570221]\n"
     ]
    }
   ],
   "source": [
    "#Evaluar modelo\n",
    "score = model.evaluate(X_test, Y_test,verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 688us/step\n",
      "17/17 [==============================] - 0s 716us/step\n",
      "17/17 [==============================] - 0s 816us/step\n",
      "8/8 [==============================] - 0s 906us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 783us/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.778 \t 0.717 \t 0.606\n",
      "  Test \t 0.710 \t 0.578 \t 0.600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "accu_train = accuracy_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "prec_train = precision_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "reca_train = recall_score(Y_train,(model.predict(X_train) > 0.5).astype(\"int32\"))\n",
    "\n",
    "\n",
    "accu_test = accuracy_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "prec_test = precision_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "reca_test = recall_score(Y_test,(model.predict(X_test) > 0.5).astype(\"int32\"))\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.782 \t 0.741 \t 0.580\n",
      "  Test \t 0.736 \t 0.617 \t 0.625\n"
     ]
    }
   ],
   "source": [
    "#Comparar contra Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train,Y_train)\n",
    "Yhat = model_log.predict(X_train)\n",
    "\n",
    "accu_train = accuracy_score(Y_train,Yhat)\n",
    "prec_train = precision_score(Y_train,Yhat)\n",
    "reca_train = recall_score(Y_train,Yhat)\n",
    "\n",
    "Yhat = model_log.predict(X_test)\n",
    "accu_test = accuracy_score(Y_test,Yhat)\n",
    "prec_test = precision_score(Y_test,Yhat)\n",
    "reca_test = recall_score(Y_test,Yhat)\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo Multiclase**\n",
    "\n",
    "- Aunque las salidas de la red neuronal están limitadas a un rango de valores entre 0 y 1, no se garantiza que la suma de estos sea igual a 1\n",
    "- Transformar las salidas para que puedan ser usadas como probabilidades ayuda mucho a la interpretabilidad de las predicciones\n",
    "- Transformación Softmax\n",
    "\n",
    "$$\\hat{p}_{l,i}^{*} = \\frac{e^{\\hat{y}_{l,i}}}{\\sum{e^{\\hat{y}_{l,i}}}}$$\n",
    "\n",
    "- $\\hat{y}_{1}=0.25$, $\\hat{y}_{2}=0.76$, $\\hat{y}_{3}=0.1$\n",
    "\n",
    "- $\\hat{p}_{1}=0.3099$, $\\hat{p}_{2}=0.4717$, $\\hat{p}_{3}=0.2184$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD, Adam\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "Y #tres tipos de flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la variable target a dummies\n",
    "dummy_y = np_utils.to_categorical(Y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 240ms/step - loss: 3.4712 - accuracy: 0.3167 - val_loss: 2.1323 - val_accuracy: 0.6333\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6849 - accuracy: 0.6667 - val_loss: 0.7672 - val_accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7967 - accuracy: 0.6583 - val_loss: 0.7813 - val_accuracy: 0.7000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8149 - accuracy: 0.6583 - val_loss: 0.7250 - val_accuracy: 0.7000\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7504 - accuracy: 0.6583 - val_loss: 0.6716 - val_accuracy: 0.7000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6914 - accuracy: 0.6667 - val_loss: 0.6088 - val_accuracy: 0.7333\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6216 - accuracy: 0.7333 - val_loss: 0.5695 - val_accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5673 - accuracy: 0.9500 - val_loss: 0.5066 - val_accuracy: 0.9667\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5156 - accuracy: 0.9250 - val_loss: 0.4715 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4717 - accuracy: 0.9833 - val_loss: 0.4362 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4484 - accuracy: 0.8500 - val_loss: 0.3879 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3888 - accuracy: 0.9667 - val_loss: 0.3524 - val_accuracy: 0.9667\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3574 - accuracy: 0.9500 - val_loss: 0.3331 - val_accuracy: 0.8667\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3604 - accuracy: 0.9083 - val_loss: 0.3995 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4259 - accuracy: 0.7833 - val_loss: 0.3362 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3698 - accuracy: 0.8333 - val_loss: 0.4218 - val_accuracy: 0.7667\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3926 - accuracy: 0.7917 - val_loss: 0.5001 - val_accuracy: 0.7667\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5760 - accuracy: 0.6833 - val_loss: 0.3736 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3420 - accuracy: 0.8583 - val_loss: 0.2363 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2414 - accuracy: 0.9667 - val_loss: 0.3067 - val_accuracy: 0.8667\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2670 - accuracy: 0.9417 - val_loss: 0.3195 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3381 - accuracy: 0.8417 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2012 - accuracy: 0.9667 - val_loss: 0.1985 - val_accuracy: 0.9667\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2025 - accuracy: 0.9750 - val_loss: 0.1884 - val_accuracy: 0.9667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1872 - accuracy: 0.9667 - val_loss: 0.1789 - val_accuracy: 0.9667\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1841 - accuracy: 0.9667 - val_loss: 0.2430 - val_accuracy: 0.8667\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2401 - accuracy: 0.9250 - val_loss: 0.2306 - val_accuracy: 0.8667\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2043 - accuracy: 0.9250 - val_loss: 0.1719 - val_accuracy: 0.9667\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2393 - accuracy: 0.9167 - val_loss: 1.0519 - val_accuracy: 0.7000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8841 - accuracy: 0.7333 - val_loss: 1.1596 - val_accuracy: 0.6333\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0464 - accuracy: 0.6750 - val_loss: 0.5480 - val_accuracy: 0.6333\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5516 - accuracy: 0.6417 - val_loss: 0.4943 - val_accuracy: 0.7000\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5475 - accuracy: 0.6583 - val_loss: 0.6245 - val_accuracy: 0.7000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6363 - accuracy: 0.6583 - val_loss: 0.7070 - val_accuracy: 0.6333\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7271 - accuracy: 0.6417 - val_loss: 0.7438 - val_accuracy: 0.7000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7070 - accuracy: 0.6417 - val_loss: 0.7212 - val_accuracy: 0.6333\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6454 - accuracy: 0.6750 - val_loss: 0.3927 - val_accuracy: 0.9333\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4044 - accuracy: 0.8917 - val_loss: 0.3726 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3947 - accuracy: 0.8333 - val_loss: 0.3682 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4035 - accuracy: 0.8417 - val_loss: 0.4014 - val_accuracy: 0.9333\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4135 - accuracy: 0.9333 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3494 - accuracy: 0.9417 - val_loss: 0.3425 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3515 - accuracy: 0.8750 - val_loss: 0.3457 - val_accuracy: 0.9333\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3462 - accuracy: 0.9583 - val_loss: 0.3794 - val_accuracy: 0.8667\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3647 - accuracy: 0.8750 - val_loss: 0.3781 - val_accuracy: 0.7667\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3914 - accuracy: 0.7167 - val_loss: 0.3132 - val_accuracy: 0.9333\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3257 - accuracy: 0.9333 - val_loss: 0.3407 - val_accuracy: 0.9333\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3460 - accuracy: 0.9333 - val_loss: 0.3213 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3197 - accuracy: 0.9000 - val_loss: 0.3508 - val_accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3465 - accuracy: 0.9417 - val_loss: 0.2963 - val_accuracy: 0.9333\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2994 - accuracy: 0.9417 - val_loss: 0.3112 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3080 - accuracy: 0.9000 - val_loss: 0.3675 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3685 - accuracy: 0.8583 - val_loss: 0.2898 - val_accuracy: 0.9333\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2975 - accuracy: 0.9750 - val_loss: 0.2863 - val_accuracy: 0.9333\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2907 - accuracy: 0.9750 - val_loss: 0.2928 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2971 - accuracy: 0.8833 - val_loss: 0.2678 - val_accuracy: 0.9667\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2778 - accuracy: 0.9583 - val_loss: 0.2706 - val_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2807 - accuracy: 0.9333 - val_loss: 0.2769 - val_accuracy: 0.9667\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2951 - accuracy: 0.9583 - val_loss: 0.3641 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3778 - accuracy: 0.7500 - val_loss: 0.2814 - val_accuracy: 0.9667\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3085 - accuracy: 0.9250 - val_loss: 0.3162 - val_accuracy: 0.9000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3112 - accuracy: 0.9000 - val_loss: 0.2966 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2930 - accuracy: 0.8833 - val_loss: 0.2626 - val_accuracy: 0.9333\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2622 - accuracy: 0.9500 - val_loss: 0.2854 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2849 - accuracy: 0.8833 - val_loss: 0.2394 - val_accuracy: 0.9667\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2380 - accuracy: 0.9667 - val_loss: 0.2740 - val_accuracy: 0.9333\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2632 - accuracy: 0.9500 - val_loss: 0.2836 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2746 - accuracy: 0.8833 - val_loss: 0.2676 - val_accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2732 - accuracy: 0.9333 - val_loss: 0.3796 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3934 - accuracy: 0.7500 - val_loss: 0.2863 - val_accuracy: 0.9000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3026 - accuracy: 0.9167 - val_loss: 0.3974 - val_accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3712 - accuracy: 0.7750 - val_loss: 0.3393 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3257 - accuracy: 0.8250 - val_loss: 0.2515 - val_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2542 - accuracy: 0.9417 - val_loss: 0.2165 - val_accuracy: 0.9667\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2202 - accuracy: 0.9500 - val_loss: 0.2301 - val_accuracy: 0.9667\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2371 - accuracy: 0.9333 - val_loss: 0.2138 - val_accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2150 - accuracy: 0.9583 - val_loss: 0.2272 - val_accuracy: 0.9667\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2305 - accuracy: 0.9333 - val_loss: 0.2110 - val_accuracy: 0.9667\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2109 - accuracy: 0.9667 - val_loss: 0.2126 - val_accuracy: 0.9667\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2100 - accuracy: 0.9667 - val_loss: 0.2547 - val_accuracy: 0.9333\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2518 - accuracy: 0.9333 - val_loss: 0.2153 - val_accuracy: 0.9667\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2127 - accuracy: 0.9667 - val_loss: 0.2518 - val_accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2366 - accuracy: 0.9250 - val_loss: 0.2546 - val_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2498 - accuracy: 0.9417 - val_loss: 0.2233 - val_accuracy: 0.9667\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2215 - accuracy: 0.9417 - val_loss: 0.2365 - val_accuracy: 0.9000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2259 - accuracy: 0.9167 - val_loss: 0.2333 - val_accuracy: 0.9333\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2350 - accuracy: 0.9417 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1959 - accuracy: 0.9750 - val_loss: 0.1921 - val_accuracy: 0.9667\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1910 - accuracy: 0.9667 - val_loss: 0.2437 - val_accuracy: 0.9333\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2415 - accuracy: 0.9500 - val_loss: 0.1968 - val_accuracy: 0.9667\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1962 - accuracy: 0.9667 - val_loss: 0.1980 - val_accuracy: 0.9667\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1919 - accuracy: 0.9750 - val_loss: 0.2339 - val_accuracy: 0.9333\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2355 - accuracy: 0.9333 - val_loss: 0.1842 - val_accuracy: 0.9667\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1853 - accuracy: 0.9667 - val_loss: 0.1887 - val_accuracy: 0.9667\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1884 - accuracy: 0.9667 - val_loss: 0.1795 - val_accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1812 - accuracy: 0.9750 - val_loss: 0.1809 - val_accuracy: 0.9667\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1811 - accuracy: 0.9667 - val_loss: 0.1783 - val_accuracy: 0.9667\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1796 - accuracy: 0.9667 - val_loss: 0.1759 - val_accuracy: 0.9667\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1772 - accuracy: 0.9667 - val_loss: 0.1750 - val_accuracy: 0.9667\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1760 - accuracy: 0.9750 - val_loss: 0.1735 - val_accuracy: 0.9667\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1748 - accuracy: 0.9667 - val_loss: 0.1716 - val_accuracy: 0.9667\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1740 - accuracy: 0.9750 - val_loss: 0.1714 - val_accuracy: 0.9667\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1752 - accuracy: 0.9583 - val_loss: 0.1695 - val_accuracy: 0.9667\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1738 - accuracy: 0.9750 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1743 - accuracy: 0.9750 - val_loss: 0.1695 - val_accuracy: 0.9667\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1699 - accuracy: 0.9667 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1771 - accuracy: 0.9750 - val_loss: 0.1652 - val_accuracy: 0.9667\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1666 - accuracy: 0.9583 - val_loss: 0.1726 - val_accuracy: 0.9667\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1712 - accuracy: 0.9667 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1794 - accuracy: 0.9583 - val_loss: 0.1662 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1720 - accuracy: 0.9667 - val_loss: 0.1651 - val_accuracy: 0.9667\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1669 - accuracy: 0.9667 - val_loss: 0.1712 - val_accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1791 - accuracy: 0.9500 - val_loss: 0.2009 - val_accuracy: 0.9667\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2060 - accuracy: 0.9333 - val_loss: 0.1862 - val_accuracy: 0.9333\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2049 - accuracy: 0.9500 - val_loss: 0.1657 - val_accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1833 - accuracy: 0.9500 - val_loss: 0.1796 - val_accuracy: 0.9667\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1732 - accuracy: 0.9750 - val_loss: 0.2187 - val_accuracy: 0.9000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2059 - accuracy: 0.9417 - val_loss: 0.2195 - val_accuracy: 0.9000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2144 - accuracy: 0.9083 - val_loss: 0.1535 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1699 - accuracy: 0.9667 - val_loss: 0.1538 - val_accuracy: 0.9667\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1629 - accuracy: 0.9583 - val_loss: 0.1608 - val_accuracy: 0.9667\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1604 - accuracy: 0.9750 - val_loss: 0.1697 - val_accuracy: 0.9667\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1724 - accuracy: 0.9583 - val_loss: 0.1547 - val_accuracy: 0.9667\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1545 - accuracy: 0.9667 - val_loss: 0.1614 - val_accuracy: 0.9667\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1662 - accuracy: 0.9500 - val_loss: 0.1546 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1585 - accuracy: 0.9583 - val_loss: 0.1507 - val_accuracy: 0.9667\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1521 - accuracy: 0.9667 - val_loss: 0.1451 - val_accuracy: 0.9667\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1509 - accuracy: 0.9667 - val_loss: 0.1516 - val_accuracy: 0.9667\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1547 - accuracy: 0.9667 - val_loss: 0.1517 - val_accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1541 - accuracy: 0.9583 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1591 - accuracy: 0.9667 - val_loss: 0.1812 - val_accuracy: 0.9667\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1823 - accuracy: 0.9583 - val_loss: 0.1579 - val_accuracy: 0.9667\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1809 - accuracy: 0.9417 - val_loss: 0.1678 - val_accuracy: 0.9667\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1785 - accuracy: 0.9667 - val_loss: 0.1842 - val_accuracy: 0.9667\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1938 - accuracy: 0.9583 - val_loss: 0.1778 - val_accuracy: 0.9667\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1733 - accuracy: 0.9750 - val_loss: 0.1874 - val_accuracy: 0.9667\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1807 - accuracy: 0.9667 - val_loss: 0.1693 - val_accuracy: 0.9667\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1699 - accuracy: 0.9667 - val_loss: 0.1485 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1512 - accuracy: 0.9750 - val_loss: 0.1504 - val_accuracy: 0.9667\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1449 - accuracy: 0.9750 - val_loss: 0.1719 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1755 - accuracy: 0.9500 - val_loss: 0.2198 - val_accuracy: 0.8667\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2180 - accuracy: 0.9083 - val_loss: 0.1520 - val_accuracy: 0.9667\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1817 - accuracy: 0.9417 - val_loss: 0.1505 - val_accuracy: 0.9667\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1516 - accuracy: 0.9667 - val_loss: 0.1943 - val_accuracy: 0.9667\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1894 - accuracy: 0.9583 - val_loss: 0.1641 - val_accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1666 - accuracy: 0.9750 - val_loss: 0.1600 - val_accuracy: 0.9667\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1592 - accuracy: 0.9667 - val_loss: 0.1474 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1475 - accuracy: 0.9833 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1409 - accuracy: 0.9833 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1371 - accuracy: 0.9833 - val_loss: 0.1434 - val_accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.1292 - val_accuracy: 0.9667\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1336 - accuracy: 0.9583 - val_loss: 0.2028 - val_accuracy: 0.9000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2119 - accuracy: 0.9333 - val_loss: 0.1268 - val_accuracy: 0.9667\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1361 - accuracy: 0.9667 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1443 - accuracy: 0.9667 - val_loss: 0.1465 - val_accuracy: 0.9667\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1559 - accuracy: 0.9583 - val_loss: 0.1397 - val_accuracy: 0.9667\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1449 - accuracy: 0.9667 - val_loss: 0.1312 - val_accuracy: 0.9667\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1320 - accuracy: 0.9750 - val_loss: 0.1495 - val_accuracy: 0.9667\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1467 - accuracy: 0.9583 - val_loss: 0.1547 - val_accuracy: 0.9667\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1532 - accuracy: 0.9667 - val_loss: 0.1302 - val_accuracy: 0.9667\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1282 - accuracy: 0.9833 - val_loss: 0.1513 - val_accuracy: 0.9333\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1537 - accuracy: 0.9583 - val_loss: 0.1305 - val_accuracy: 0.9667\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1314 - accuracy: 0.9667 - val_loss: 0.1387 - val_accuracy: 0.9667\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1376 - accuracy: 0.9750 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1307 - accuracy: 0.9833 - val_loss: 0.1255 - val_accuracy: 0.9667\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.1319 - val_accuracy: 0.9667\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1332 - accuracy: 0.9667 - val_loss: 0.1210 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1300 - accuracy: 0.9750 - val_loss: 0.1213 - val_accuracy: 0.9667\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1255 - accuracy: 0.9750 - val_loss: 0.1292 - val_accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1344 - accuracy: 0.9667 - val_loss: 0.1399 - val_accuracy: 0.9667\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1403 - accuracy: 0.9667 - val_loss: 0.1361 - val_accuracy: 0.9667\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1472 - accuracy: 0.9667 - val_loss: 0.1350 - val_accuracy: 0.9667\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1536 - accuracy: 0.9583 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1379 - accuracy: 0.9500 - val_loss: 0.1575 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1564 - accuracy: 0.9667 - val_loss: 0.1719 - val_accuracy: 0.9667\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1658 - accuracy: 0.9583 - val_loss: 0.1191 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1310 - accuracy: 0.9583 - val_loss: 0.1177 - val_accuracy: 0.9667\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1223 - accuracy: 0.9667 - val_loss: 0.1567 - val_accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1473 - accuracy: 0.9583 - val_loss: 0.2498 - val_accuracy: 0.8333\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2596 - accuracy: 0.9000 - val_loss: 0.1457 - val_accuracy: 0.9667\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1831 - accuracy: 0.9500 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1388 - accuracy: 0.9500 - val_loss: 0.2194 - val_accuracy: 0.8667\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2071 - accuracy: 0.9167 - val_loss: 0.2078 - val_accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1981 - accuracy: 0.9333 - val_loss: 0.1191 - val_accuracy: 0.9667\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1226 - accuracy: 0.9750 - val_loss: 0.1268 - val_accuracy: 0.9667\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1191 - accuracy: 0.9833 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1185 - accuracy: 0.9833 - val_loss: 0.1240 - val_accuracy: 0.9667\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1268 - accuracy: 0.9667 - val_loss: 0.1271 - val_accuracy: 0.9667\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1327 - accuracy: 0.9667 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1156 - accuracy: 0.9667 - val_loss: 0.1653 - val_accuracy: 0.9667\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1593 - accuracy: 0.9667 - val_loss: 0.1263 - val_accuracy: 0.9667\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1202 - accuracy: 0.9750 - val_loss: 0.1466 - val_accuracy: 0.9667\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1500 - accuracy: 0.9667 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1329 - accuracy: 0.9583 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.1426 - val_accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1510 - accuracy: 0.9583 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1352 - accuracy: 0.9667 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1271 - accuracy: 0.9833 - val_loss: 0.1359 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "#Construcción de la red neuronal\n",
    "\n",
    "# neural network structure\n",
    "model = Sequential()\n",
    "model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Gradiente descendente\n",
    "learning_rate=0.1\n",
    "epochs = 200\n",
    "momentum = 0.8\n",
    "decay_rate = learning_rate/epochs\n",
    "sgd = SGD(lr=learning_rate, decay=decay_rate, momentum=momentum)\n",
    "\n",
    "# configuracion del optimizador\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# entrenamiento de la red neuronal\n",
    "#history = model.fit(X, dummy_y,epochs=200, batch_size=100, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=100, \n",
    "                   validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficar el categorical crossentropy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predecir con el modelo\n",
    "#Y_pred = model.predict_classes(X)\n",
    "#Y_prob = model.predict_proba(X)\n",
    "\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_prob = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.45731542e-08, 7.32857883e-01, 2.67142117e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [1.14576044e-25, 2.52139609e-04, 9.99747813e-01],\n",
       "       [7.57336149e-09, 6.66866064e-01, 3.33133936e-01],\n",
       "       [8.44345838e-09, 6.73250973e-01, 3.26749057e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [3.55305383e-04, 9.75853205e-01, 2.37915237e-02],\n",
       "       [1.18132416e-14, 7.23404139e-02, 9.27659631e-01],\n",
       "       [4.52372619e-11, 3.51976931e-01, 6.48023069e-01],\n",
       "       [2.25962922e-05, 9.48815227e-01, 5.11621721e-02],\n",
       "       [4.61363640e-13, 1.53907731e-01, 8.46092284e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [1.67374097e-08, 7.12129474e-01, 2.87870556e-01],\n",
       "       [2.99866724e-19, 7.01845204e-03, 9.92981553e-01],\n",
       "       [8.27607073e-06, 9.32933509e-01, 6.70582056e-02],\n",
       "       [1.44428549e-08, 7.03953147e-01, 2.96046793e-01],\n",
       "       [4.19359012e-19, 7.56647019e-03, 9.92433548e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [3.30032074e-12, 2.24240869e-01, 7.75759161e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [1.93597404e-18, 1.06564322e-02, 9.89343643e-01],\n",
       "       [2.11735240e-15, 5.00113294e-02, 9.49988663e-01],\n",
       "       [5.00025413e-16, 3.65176499e-02, 9.63482320e-01],\n",
       "       [2.84559747e-18, 1.16144270e-02, 9.88385558e-01],\n",
       "       [4.36766459e-19, 7.63575453e-03, 9.92364287e-01],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05],\n",
       "       [9.55628455e-01, 4.43274640e-02, 4.41182237e-05]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse\n",
    "uniques, ids = np.unique(Y, return_inverse=True)\n",
    "dummy_y = np_utils.to_categorical(ids, len(uniques))\n",
    "reverse = uniques[dummy_y.argmax(1)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reverse,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "       1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.967 \t 0.970 \t 0.967\n",
      "  Test \t 0.967 \t 0.969 \t 0.967\n"
     ]
    }
   ],
   "source": [
    "#Más métricas corregido\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,f1_score)\n",
    "Y_proba= model.predict(X_train)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_train = accuracy_score(y_train, Y_pred)\n",
    "prec_train = precision_score(y_train, Y_pred,average='weighted')\n",
    "reca_train = recall_score(y_train, Y_pred,average='weighted')\n",
    "\n",
    "Y_proba= model.predict(X_test)\n",
    "Y_pred= np.argmax(Y_proba, axis=1)\n",
    "\n",
    "accu_test = accuracy_score(y_test, Y_pred)\n",
    "prec_test = precision_score(y_test, Y_pred,average='weighted')\n",
    "reca_test = recall_score(y_test, Y_pred,average='weighted')\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t Accu \t Prec \t Reca\n",
      " Train \t 0.975 \t 0.977 \t 0.975\n",
      "  Test \t 1.000 \t 1.000 \t 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Comparar contra Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(X_train,y_train)\n",
    "Yhat = model_log.predict(X_test)\n",
    "\n",
    "accu_train = accuracy_score(y_train,model_log.predict(X_train))\n",
    "prec_train = precision_score(y_train,model_log.predict(X_train),average='weighted')\n",
    "reca_train = recall_score(y_train,model_log.predict(X_train),average='weighted')\n",
    "\n",
    "accu_test = accuracy_score(y_test,model_log.predict(X_test))\n",
    "prec_test = precision_score(y_test,model_log.predict(X_test),average='weighted')\n",
    "reca_test = recall_score(y_test,model_log.predict(X_test),average='weighted')\n",
    "\n",
    "print(' \\t Accu \\t Prec \\t Reca\\n Train \\t %0.3f \\t %0.3f \\t %0.3f\\n  Test \\t %0.3f \\t %0.3f \\t %0.3f'%(accu_train,prec_train,reca_train,accu_test,prec_test,reca_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
